import os
import torch
from torch.utils.data import DataLoader
import pandas as pd
from collections import defaultdict
from dataset import LandmarkGraphDataset
from model import FERGCN  # ä½ çš„GCNæ¨¡å‹

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
data = "FER-2013"

# === é…ç½® ===
batch_size = 32
num_classes = 8  # æ ¹æ®ä½ çš„æ•°æ®é›†è°ƒæ•´ï¼šRAF-DB é€šå¸¸æ˜¯ 8 ç±»

# RAF-DB çš„æ ‡å‡† 7 ç±»æƒ…ç»ªæ ‡ç­¾ï¼ˆè¯·æ ¹æ®ä½ å®é™…çš„ label æ˜ å°„è°ƒæ•´ï¼ï¼‰
label_map = {
    0: 'Neutral',
    1: 'Happy',
    2: 'Sad',
    3: 'Surprise',
    4: 'Fear',
    5: 'Disgust',
    6: 'Anger',
    7: 'Contempt'  # å¦‚æœæœ‰ç¬¬8ç±»ï¼Œè¯·å–æ¶ˆæ³¨é‡Š
}
# ==================

# æ¨¡å‹è·¯å¾„
model_path = f"fergcn_model_{data}.pth"

# === æ–°å¢ï¼šæ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ ===
if not os.path.exists(model_path):
    raise FileNotFoundError(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {os.path.abspath(model_path)}\nè¯·å…ˆè®­ç»ƒæ¨¡å‹å¹¶ä¿å­˜ã€‚")
else:
    print(f"âœ… åŠ è½½æ¨¡å‹: {model_path} ({os.path.getsize(model_path) / 1e6:.2f} MB)")
# ===================================

# åŠ è½½æ¨¡å‹
model = FERGCN(num_classes=num_classes).to(device)  # ç¡®ä¿ FERGCN æ”¯æŒ num_classes å‚æ•°
model.load_state_dict(torch.load(model_path, map_location=device))
model.eval()

def run_prediction(split_name):
    """å¯¹ train/val/test ä¸€ä¸ª split è¿›è¡Œé¢„æµ‹ï¼Œå¹¶è¿”å›ç»“æœåŠæ ‡ç­¾åˆ—è¡¨"""
    dataset = LandmarkGraphDataset(f"./landmarks_{data}/{split_name}")
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)

    results = []
    true_labels_all = []
    pred_labels_all = []

    with torch.no_grad():
        for nodes, adjs, labels, paths in loader:
            nodes, adjs, labels = nodes.to(device), adjs.to(device), labels.to(device)
            outputs = model(nodes, adjs)
            _, preds = torch.max(outputs, 1)

            # æ”¶é›†ç»“æœ
            for p, true, pred in zip(paths, labels.cpu().numpy(), preds.cpu().numpy()):
                results.append([split_name, p, true, pred])
                true_labels_all.append(true)
                pred_labels_all.append(pred)

    return results, true_labels_all, pred_labels_all

# æ‰§è¡Œé¢„æµ‹
all_results = []
all_true_labels = []
all_pred_labels = []

for split in ["val"]:  # å¯æ‰©å±•ä¸º ["train", "val", "test"]
    print(f"æ­£åœ¨é¢„æµ‹ {split} ...")
    results, true_labels, pred_labels = run_prediction(split)
    all_results.extend(results)
    all_true_labels.extend(true_labels)
    all_pred_labels.extend(pred_labels)

# === è®¡ç®—å¹¶æ‰“å°å‡†ç¡®ç‡ ===
total_correct = sum(1 for t, p in zip(all_true_labels, all_pred_labels) if t == p)
total_samples = len(all_true_labels)
overall_acc = total_correct / total_samples if total_samples > 0 else 0.0

print("\n" + "="*60)
print(f"ğŸ“Š æ•´ä½“å‡†ç¡®ç‡ (Overall Accuracy): {overall_acc:.4f} ({total_correct}/{total_samples})")
print("="*60)

# æ¯ç±»å‡†ç¡®ç‡
per_class_correct = defaultdict(int)
per_class_total = defaultdict(int)

for t, p in zip(all_true_labels, all_pred_labels):
    per_class_total[t] += 1
    if t == p:
        per_class_correct[t] += 1

print("\nğŸ“ˆ å„ç±»åˆ«è¡¨æƒ…è¯†åˆ«å‡†ç¡®ç‡:")
print("-" * 60)
for class_id in range(num_classes):
    class_name = label_map.get(class_id, f"Class {class_id}")
    total = per_class_total[class_id]
    correct = per_class_correct[class_id]
    if total > 0:
        acc = correct / total
        print(f"{class_id:>2d} ({class_name:>12}): {acc:.4f} ({correct:>4d}/{total:>4d})")
    else:
        print(f"{class_id:>2d} ({class_name:>12}): N/A (0/0)")
# ==========================

# ä¿å­˜ç»“æœåˆ° Excel
df = pd.DataFrame(all_results, columns=["split", "image_path", "true_label", "pred_label"])
output_file = f"predict_{data}_val.xlsx"
df.to_excel(output_file, index=False)

print("\n" + "="*60)
print(f"âœ… æ‰€æœ‰é¢„æµ‹å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°: {output_file}")
print("="*60)
